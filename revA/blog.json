{
	"error":0,
	"posts":
	[
		{
			"title":"My First Blog Post",
			"postdt":"September 1st, 2013",
			"content": "Well this is my first blog post on the new website.  I suppose I should take a moment to tell the story of how the site came to be.  I have a number of domains registered with [Name Cheap](http://namecheap.com \"Name Cheap\") so I find myself going to their website often.  Side note: I would highly recommend them as a registrar, they have been fantastic to me.  So a few weeks ago I went to their website and saw they had *.me domains for $0.99 for the first year, and you get an email address!  I figured, how could I not ...\n\nAfter registering timduffy.me, I put up a static html page that was simply:\n\n    \n\n      <html>\n      <body>\n        <center><h1>TimDuffy.Me</h1></center>\n      </body>\n      </html>\n    \n\nI know someone reading this just twitched when they read that center tag, :D.  I figured it was good enough since what I really wanted was the email address.\n\nAfter a few days (read: weeks) I figured I should probably get around to putting something more meaningful up on the site since I was giving my new email address out to people, I didn't want them to be disappointed when they went to the domain :p.\n\nI started down the path of trying to write a very simple CMS/Blog website using pyramid (a python web framework) that would be based around the blog being written in Markdown, and then rendered.  I needed to, however, come up to speed on a number of technologies before I could do this:  pyramid (and it's rendering engine), SQLAlchemy, and Markdown.  I dove in.  I got lost.  I gave up.\n\nSo what you are looking at here is flat html based website with some JQuery JavaScript that pulls blog posts from a json file that sits on the server (Apache2) - nothing fancy.  Feel free to take a look at the code here: [timduffy.me](https://github.com/thequbit/timduffy.me \"TimDuffy.me\").\n"
		},
		{
			"title":"Syracuse Hacks and Hackers Meet-Up",
			"postdt":"September 5th, 2013",
			"content": "Yesterday, Wednesday 9/5/13, I joined a bunch of great people in Syracuse, NY at the new (at the time of this blog post) Syracuse Media Group ( operators of http://syracuse.com/ website ) for a Hacks and Hackers Syracuse Meet-Up.  The title of the Meet-Up was \"Brainstorm Civic Data Projects\", which I think we did!\n\nI was asked by Dan Pacheco, the founder of Hacks and Hackers Syracuse as well as the \"Chair of Journalism Innovation at SU's Newhouse school\" - taken from his meetup.com profile.\n\n###Cuse Data###\nDan asked me to speak about some of the work I had done with some crime data that is posted with just a few days of delay to syrcuse.com.  You can checkout the live example [here](http://mycodespace.net/projects/cusedata/ \"here\").  The data source can be found [here](http://www.syracuse.com/crime/police-reports/ \"here\").  And, of course, the source code can be found [here](https://github.com/thequbit/syracusedatascraper \"here\").\n\nThe original objective for this project was to pull in Onondaga County crime data, and overlay abandoned building locations - create some kind of heat map.  Unfortunately this project kind of got put on hold, but I would very much so like to revisit it.  Like all data sets, there is usually something else interesting nested in there somewhere ... you just need to find a way to visualize it correctly :D.\n\n###Barking Owl###\n\nI also talked about a current Hacks and Hackers Rochester project called 'Barking Owl'.  The source code can be found [here](https://github.com/thequbit/barkingowl \"here\").  BarkingOwl is a project that will scrape any website that is passed in by the user and pull out all of the PDF files for that URL.  It will then search those PDF's for keywords and/or phrases.  Think: \"Tell me when the town of Dansville, NY is talking about 'fracking'\".\n\nThe project is largely based off of work I did on [Monroe Minutes](http://monroeminutes.org \"Monroe Minutes\") ([source](https://github.com/thequbit/monroeminutes \"source\")).  From that project, a small tool called PDFImp ([source](https://github.com/thequbit/pdfimp \"PDFImp\")) was born.  PDFImp will pull from any URL any link that leads to a PDF (note that this could result in a redirect and it will still return the link), as well as the text of that a tag.  Here is an example usage of PDFImp:\n\n    >>> from pdfimp import pdfimp\n    >>>\n    >>> imp = pdfimp()\n    >>> siteurl = \"http://www.example.com/\"\n    >>> links = imp.getpdfs(maxlevel=2,siteurl=url,links=[url])\n    >>> print links\n\nThis would produce a list of tuples: (pdfurl,linktext), where pdfurl is the url of the PDF, and linktext is the text found in the a tag that lead to the PDF.\n\nAt the time of this blog post, BarkingOwl uses a database access layer produced by the sql2api ([source](https://github.com/thequbit/sql2api \"source\")) tool.  I would like to do two things in the near future:\n\n - Convert BarkingOwl scraper over to use [SQLAlchemy](http://www.sqlalchemy.org/ \"SQLAlchemy\")\n - Create a Pyramid based web front-end for users to enter new URLs and phrases into the database.\n\nThe first item will bring BarkingOwl into the realm of an 'industry standard' method of DB access (although I still prefer my sql2api method ...).\n\nThe second item will allow someone other than me with terminal access to actually use the tool ... ha.\n\nFor those interested, here is the link to the presentation that I gave at the HHSyracuse meetup:\n\n[Syracuse.com/hh Syracuse meetup](http://bit.ly/18E8rSO \"Syracuse.com/hh Syracuse meetup\")\n\n-TD\n"
		}
	]
	
}